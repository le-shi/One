# https://awesome-prometheus-alerts.grep.to/rules
groups:
# ceph本身的prometheus插件
- name: ceph
  rules:
  - alert: Ceph 状态
    expr: ceph_health_status != 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: "Ceph 状态 (instance {{ $labels.instance }})"
      description: "Ceph 实例不健康\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: Ceph 监视器时钟偏差
    expr: abs(ceph_monitor_clock_skew_seconds) > 0.2
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Ceph 监视器时钟偏差 (instance {{ $labels.instance }})"
      description: "检测到 Ceph 监视器时钟偏差。请检查ntp和硬件时钟设置\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: CephMonitorLowSpace
    expr: ceph_monitor_avail_percent < 10
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Ceph monitor low space (instance {{ $labels.instance }})"
      description: "Ceph monitor storage is low.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: Ceph的Osd节点挂了
    expr: ceph_osd_up == 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: "Ceph的Osd节点挂了 (instance {{ $labels.instance }})"
      description: "Ceph 对象存储守护进程关闭\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: Ceph Mon节点故障
    expr: sum(ceph_mon_quorum_status == 1) / sum(ceph_mon_quorum_status) < 0.5
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: "Ceph Mon 节点故障 (instance {{ $labels.instance }})"
      description: "Ceph Mon 法定人数过半故障\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: Ceph OSD 高延迟
    expr: ceph_osd_perf_apply_latency_seconds > 5
    for: 1m
    labels:
      severity: warning
    annotations:
      summary: "Ceph OSD 高延迟 (instance {{ $labels.instance }})"
      description: "Ceph 对象存储守护进程延迟很高。请检查它是否没有卡在奇怪的状态。\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: Ceph OSD 空间过低
    expr: ceph_osd_utilization > 90
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Ceph OSD 空间过低 (instance {{ $labels.instance }})"
      description: "Ceph 对象存储守护进程空间不足(<10%)。请添加更多磁盘。\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: CephOsdReweighted
    expr: ceph_osd_weight < 1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Ceph OSD 重新分配权重 (instance {{ $labels.instance }})"
      description: "Ceph 对象存储守护进程需要太多时间来调整大小。\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: CephPgDown
    expr: ceph_pg_down > 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: "Ceph PG down (instance {{ $labels.instance }})"
      description: "Some Ceph placement groups are down. Please ensure that all the data are available.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: CephPgIncomplete
    expr: ceph_pg_incomplete > 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: "Ceph PG incomplete (instance {{ $labels.instance }})"
      description: "Some Ceph placement groups are incomplete. Please ensure that all the data are available.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: CephPgInconsistant
    expr: ceph_pg_inconsistent > 0
    for: 0m
    labels:
      severity: warning
    annotations:
      summary: "Ceph PG inconsistant (instance {{ $labels.instance }})"
      description: "Some Ceph placement groups are inconsitent. Data is available but inconsistent across nodes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: CephPgActivationLong
    expr: ceph_pg_activating > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Ceph PG activation long (instance {{ $labels.instance }})"
      description: "Some Ceph placement groups are too long to activate.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: CephPgBackfillFull
    expr: ceph_pg_backfill_toofull > 0
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "Ceph PG backfill full (instance {{ $labels.instance }})"
      description: "Some Ceph placement groups are located on full Object Storage Daemon on cluster. Those PGs can be unavailable shortly. Please check OSDs, change weight or reconfigure CRUSH rules.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

  - alert: CephPgUnavailable
    expr: ceph_pg_total - ceph_pg_active > 0
    for: 0m
    labels:
      severity: critical
    annotations:
      summary: "Ceph PG unavailable (instance {{ $labels.instance }})"
      description: "Some Ceph placement groups are unavailable.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
